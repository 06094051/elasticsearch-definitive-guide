[[analysis]]
== Analysis – preparing data for searching

Textual data comes in many different forms: prose, computer code, different
languages, URLs, emails, file paths, postcodes etc. Elasticsearch makes sense
of these different formats by analysing textual data into terms. This chapter
explains the analysis process and how to customize to suit the data and
seach requirements.

=== How does Elasticsearch store our data?
* “text” vs “terms”
* Analysis of data and search terms
* Inverted index

=== Built in analyzers
* Keyword
* Standard vs Simple vs Whitespace vs Stop
* Stemming Language vs Snowball
* Pattern

=== Using an analyzer
* Defining an analyzer
* Testing an analyzer
* Applying an analyzer
** index time
** search time

=== Building a custom analyzer

==== Analysis process
* Character filters
* Tokenizers
* Token filters

==== Character filters
* HTML strip
* Character mapping

==== Tokenizers
* Keyword
* Standard vs Letter vs Lowercase vs Whitespace vs UAX-URL-Email
* NGram vs Edge NGram
* Pattern
* Path hierarchy

==== Token filters
===== Common
* Standard
* Lowercase
* ASCII folding
* Stop
* Synonyms

===== Language specific
* Stemmer vs Porter Stem vs KStem vs Snowball
* Compound Word
* Elision
* Phonetic

===== NGram vs Edge Ngram vs Shingle

===== Regular expressions
* Word delimiter
* Pattern replace

===== Other
* Length
* Unique
* Reverse

=== Living in a Unicode world – ICU plugin

==== Normalization
==== Case and diacritic folding
==== Collation



