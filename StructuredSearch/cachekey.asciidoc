In the Lookup example, we saw an option called `_cache_key`.  This isn't unique
to the `terms` Lookup filter...its an option that can be set for any filter.
It allows you to give filters human-sensible names, which Elasticsearch will
then use internally.

Custom cache keys has a single edge-case purpose: potentially huge reductions
in memory.  That seems strange, since it is just a cache key, so let's look
at how Elasticsearch works internally.

By default, Elasticsearch uses the filter itself as a key in a map.  When
parsing a query, it can simply take the entire filter contents, use that as a
key and retrieve the associated bitset from memory.

As a simple example, a filter map may look like this:


[rame="topbot",options="header"]
|======================
|Terms |Key | Bitset
|`marketing` | "marketing" |01101011001010
|`sales`, `pr` | "sales_pr" |11010011111011
|`management`, `sales`, `pr` | "management_sales_pr" |11110111111011
|`engineering` | "engineering" |00000011001010
|======================

As you can see, we have a list of `terms` filters.  The key to the map is simply
the list of terms concatenated together.  Elasticsearch does this for one 
reason: speed.  It is very fast to extract the filter contents and retrieve from
the map. 

This does, however, lead to certain edge-cases where memory usage can balloon
out of control.  What happens if you have 10,000 terms in your filter?

Elasticsearch will simply concatenate all 10,000 terms together...which means
the key itself may potentially use more memory than the cached bitset!  Obviously,
this is not ideal.

As we saw with `terms` lookup, it was highly recommended that the user specify
a `_cache_key` value for this exact reason.  In practice, it is usually only the
`Terms` filter which is susceptible to this memory problem, since it is the
only filter that can potentially contain a large number of terms concatenated
together.

If you are using the `terms` filter (including the lookup derivation), analyze
your filters carefully and assess if you need to set a custom `_cache_key`.

If you happen to have a very large term set, set the `_cache_key` to
something that makes sense for your business logic, or simply hash the terms
with something like SHA1.

.Is this reported in the memory stats?
****
Unfortunately, cache key values are not included in the memory usage stats that
Elasticsearch provides.  While you can see how much memory the Filter cache is
using, this does not include memory used by the cache keys themselves.

The only good way to diagnose this situation is to carefully examine the filters
that you are executing and determine if a custom `_cache_key` is required.
****