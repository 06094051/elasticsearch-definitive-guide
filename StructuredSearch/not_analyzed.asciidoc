
=== Understanding not_analyzed

In many structured search situations, it makes sense to map a field
as `not_analyzed`.  The `not_analyzed` property does what it says on the tin...
it prevents a field from being analyzed by one of the various analyzers.

The string will go into the index exactly as it appears: capitalization, punctuation
and all.  Phrased another way, `not_analyzed` ensures that only exact matches will
be returned.  Let's look at an example of when you might want to do this.

This document represents an electronic device, and has a serial number of some type:

    {
        "product_name" : "Widget ABC",
        "serial" : "12JE7612-19238-BJ#J/XY9"
    }

If you were to index that document with the Standard Analyzer, your serial number would
be indexed as the following tokens:

    $ curl -XGET 'localhost:9200/_analyze?analyzer=standard&pretty' -d '12JE7612-19238-BJ#J/XY9'

    {
      "tokens" : [ {
        "token" : "12je7612",
        "start_offset" : 0,
        "end_offset" : 8,
        "type" : "<ALPHANUM>",
        "position" : 1
      }, {
        "token" : "19238",
        "start_offset" : 9,
        "end_offset" : 14,
        "type" : "<NUM>",
        "position" : 2
      }, {
        "token" : "bj",
        "start_offset" : 15,
        "end_offset" : 17,
        "type" : "<ALPHANUM>",
        "position" : 3
      }, {
        "token" : "j",
        "start_offset" : 18,
        "end_offset" : 19,
        "type" : "<ALPHANUM>",
        "position" : 4
      }, {
        "token" : "xy9",
        "start_offset" : 20,
        "end_offset" : 23,
        "type" : "<ALPHANUM>",
        "position" : 5
      } ]
    }

As you can see, the Standard Analyzer interpreted each hyphen, hash mark and slash as a place to
split the string into a new token.  It also lowercased all the characters.

If you searched for "12JE7612-ABCD-EFG", you would not expect it to match because they are
blatantly different serial numbers.  However, since Elasticsearch tokenized and indexed
the serial number, the first part of your query ("12JE7612") very well may match, returning
unexpected products.

If instead you map that field as not analyzed:

    curl -XPUT localhost:9200/products/product/_mapping -d '
    {
        "product" : {
            "properties" : {
                "serial" : {"type" : "string", "index" : "not_analyzed"}
            }
        }
    }'

Then the serial number will only be indexed as a single token:

    {
      "tokens" : [ {
        "token" : "12JE7612-19238-BJ#J/XY9",
        "start_offset" : 0,
        "end_offset" : 23,
        "type" : "word",
        "position" : 1
      } ]
    }

And now only exact matches will actually match. Great!