
Earlier in this chapter (<<_internal_filter_operation>>) we briefly discussed
how filters are calculated.  At their heart is a bitset representing which
documents match the filter.

Elasticsearch aggressively caches these bitsets for later use.  Once cached,
these bitsets can be reused anywhere the filter is used, without having to
re-evaluate the entire filter again.

These cached bitsets are also handled in such a way that they are incrementally
updated.  As you index new documents, only new documents need to be added to the
existing bitsets (rather than recomputing the entire cached filter over and over).
Basically, the filters in Elasticsearch are real-time like the rest of the
system.

==== Independent filter caching

Filters are cached independently from the eachother and the query that they
reside in, which makes them reusable in many different contexts.  
If two different queries use the same filter, the same filter bitset will be 
reused.  Likewise, if a single query uses the same filter in multiple places,
only one bitset is calculated.  Let's look at this example query:

[source,js]
--------------------------------------------------
GET /my_store/products/_search
{
   "query" : {
      "filtered" : {
         "filter" : {
            "bool" : {
              "should" : [
                "bool" : {
                  "must" : [
                    "term" : {"tag" : "search"}, <1>
                    "term" : {"type" : "open source"}
                  ]  
                },
                "bool" : {
                  "must" : [
                    "term" : {"tag" : "search"}, <1>
                    "term" : {"year" : 2013}
                  ]  
                }
              ]
           }
         }
      }
   }
   
}
--------------------------------------------------
<1> These two filters are identical and will use the same bitset

The query is a set of two nested `bool` filters.  One filter is looking for
`tag:search AND type:"open source"`, while the other is looking for `tag:search
AND year:2013`.  They both utilize the same filter for the `tag` field, 
which means the bitset for `tag:search` is only generated once and then used
in both places.

This ties in nicely with the composability of the query DSL.  It is easy to
move filters around, or reuse the same filter in multiple places within the
same query.  This isn't just convenient to the developer -- it has direct
performance benefits because the bitsets are reused internally.

==== Controlling caching

The vast majority of filters are cached by default.  There are few exceptions,
the most notable being the `bool` filter.

By default, the `bool` filter *is not* cached.  In practice, most compound
filters are dynamically generated by your application.  The constituents of the
filter changes from query to query, so it doesn't make much sense to cache the
entire `bool`.  Rather, we'll just leverage the cached filters that make up
the `bool`, which is nearly always more efficient.

Geo filters are also uncached by default, because they perform calculations that
are relative to the specified parameters.  It often doesn't make sense
to cache these filters, since they are rarely the same.

Otherwise, every other filter is cached by default.

Sometimes, however, it makes sense to override the default caching behavior.
For example, recall the range filter example that dealt with dates:

[source,js]
--------------------------------------------------
GET /my_store/products/_search
{
    "query" : {
        "filtered" : {
            "filter" : {
                "range" : {
                    "timestamp" : {
                        "gt" : "now-1h"
                    } 
                }
            }
        }
    }
}
--------------------------------------------------

This is not a cacheable filter.  `Now` is a moving target that will change every
millisecond.  Every time this filter is executed, it must re-evaluate the
filter against the entire dataset.  Rather than gaining performance, this filter
will likely hurt your performance and cause your filter cache to churn 
constantly (which will hurt other, useful filters).

If you have a filter like the above, it makes sense to disable caching for that
particular filter.  This is done by setting the `_cache` option to false:

[source,js]
--------------------------------------------------
GET /my_store/products/_search
{
    "query" : {
        "filtered" : {
            "filter" : {
                "range" : {
                    "timestamp" : {
                        "gt" : "now-1h"
                    },
                    "_cache" : false <1>
                }
            }
        }
    }
}
--------------------------------------------------
<1> Disable caching for this particular filter

The filter will now operate identically as before, but will not save the bitset
to memory.  This will avoid the bad behavior of churning your cache constantly.

But this introduces a problem.  A lot of the performance benefits of filters
come from caching, so how can we leverage caching _and_ avoid churning the
cache in this situation?

When you encounter these types of problems, it is usually possible to cache
another filter that operates on a larger granularity.  This is a very 
powerful pattern.  Consider this example:


[source,js]
--------------------------------------------------
GET /my_store/products/_search
{
    "query" : {
        "filtered" : {
            "filter" : {
                "bool" : {
                    "must" : [ <1>
                        {
                            "range" : {
                                "timestamp" : {
                                    "gt" : "now/d" <2>
                                }
                            }
                        },
                        {
                            "range" : {
                                "timestamp" : {
                                    "gt" : "now-1h" <3>
                                },
                                "_cache" : false 
                            }
                        }
                    ]
                }
                
            }
        }
    }
}
--------------------------------------------------
<1> We are using a `bool` filter to combine two filters that both must match
<2> The first `range` filter has a one-day granularity (`/d` floors the value
to today).  This filter is cached
<3> The second `range` filter has our previous one-hour granularity, which we
don't cache

The first `range` filter has the granularity of a single day. Since the value of 
`now` is floored to today, it remains static until tomorrow.  This makes the 
filter very cacheable since it is is valid for 24 hours.  The cached filter is 
likely to be reused throughout the course of the day.  

The second `range` is our fine, one-hour granularity filter which has a "moving"
`now`.  Unlike the first filter, this `now` is not floored, which means it changes
every millisecond.  This filter is not cacheable (since it changes so often),
therefore we set `_cache: false`.

By combining a "large granularity" filter with a "small granularity", we can 
leverage the performance benefits of filters while still avoiding the cache
churn problem.  The first filter will effectively filter out the majority of
your documents very quickly, while the second filter will fine-tune the remaining
results.

When constructing filters, especially those dealing with time, take a moment
to consider how cacheable it is.  Adjust the filters as necessary to avoid
filters that churn your cache.


==== Term's Execution Mode

In addition to `_cache`, the `terms` filter has another configuration option
which affects the internal caching behavior.  If you think about the `terms`
filter conceptually, it is basically a bunch of individual `term` filters that
are being evaluated.  The question boils down to this: how do we treat
the bitsets for each individual term?  Do we cache them together or separately?

The option, named `execution_mode`, controls this behavior.  By default
the execution mode is `plain`, which caches all the individual terms together.
As the `terms` filter is evaluating each individual term, it maintains a single
bitset which is modified.  Imagine we have four documents, and are looking for
the terms `abc` and `xyz`:

1. The term `abc` is found in the first document.  The bitset is now [1,0,0,0]
2. The term `xyz` is found in the third document.  The bitset is now [1,0,1,0]

When the filter is done executing, you are left with a single bitset that 
represents the union of _all_ the terms.

The other option is called `bool`, and it maintains a unique bitset for each
individual term.  Instead of modifying a single bitset, each term gets its own
bitset.  These bitsets are then cached individually in memory.  Using the same
example as above:

1. The term `abc` is found in the first document.  The bitsets are now 
abc:[1,0,0,0] xyz:[0,0,0,0]
2. The term `xyz` is found in the third document.  The bitsets are now 
abc:[1,0,0,0] xyz:[0,0,1,0]

These two bitsets are cached individually in memory, and the result of the filter
is the bitwise AND of both bitsets (equaling `[1,0,1,0]`).

So which do you pick?  The default execution mode (`plain`) works very well
in the majority of cases.  If you are unsure, just stick with the default.
The reason to choose `bool` over `plain` is based on how often terms clump
together in your filters.

If the same set of terms always appear together in your `terms` filter, caching
the "total" set via `plain` will be the most efficient.  If, instead, terms are
rarely arranged in the same combination, use `bool`.  Whe the terms are constantly
changing,  the "total" set of terms will rarely be used again (much like we 
discussed with the range filter on time).  It makes more sense to cache the 
bitsets independently to avoid cache churn.


