When working with exact values, you will be working with filters. Filters are 
important because they are very, very fast.  Filters do not
calculate relevance (avoiding the entire scoring phase) and are easily cached.
We'll talk about the performance benefits of filters later in 
<<_all_about_caching>>, but for now, just keep in mind that you should
use filters as often as you can.

==== Term Filter with Numbers

We are going to explore the `term` filter first because you will use it often.  
This filter is capable of handling numbers numbers, dates and text.

Let's look at an example using numbers first by indexing some products.  These
documents have a `price` and a `productID`:

[source,js]
--------------------------------------------------
POST /my_store/products/_bulk
{ "index": { "_id": 1 }}
{ "price" : 10, "productID" : "XHDK-A-1293-#fJ3" }
{ "index": { "_id": 2 }}
{ "price" : 20, "productID" : "KDKE-B-9947-#kL5" }
{ "index": { "_id": 3 }}
{ "price" : 30, "productID" : "JODL-X-1937-#pV7" }
{ "index": { "_id": 4 }}
{ "price" : 30, "productID" : "QQPX-R-3956-#aD8" }
--------------------------------------------------

Our goal is to find all products with a certain price.  You may be familiar
with SQL if you are coming from a relational database background.  If we
expressed this query as an SQL query, it would look like this:

[source,sql]
--------------------------------------------------
SELECT document
FROM products
WHERE price = 20
--------------------------------------------------

In Elasticsearch DSL, we use a `term` filter to accomplish the same thing.  The
`term` filter will look for the exact value that we specify.  By itself, a
`term` filter is very simple:

[source,js]
--------------------------------------------------
"term" : {
    "price" : 20 
}
--------------------------------------------------

The `term` filter simply specifies a field and the value that we wish to find.  

The `term` filter isn't very useful on its own though.  As discussed in the 
Search chapter (<<_empty_search>>), the `search` API expects a query and not a 
`filter`. To use our `term` filter, we need to wrap it with a 
<<_literal_filtered_literal_query>>:

[source,js]
--------------------------------------------------
GET /my_store/products/_search
{
    "query" : {
        "filtered" : { <1>
            "query" : { 
                "match_all" : {} <2>
            }, 
            "filter" : {
                "term" : { <3>
                    "price" : 20 
                }
            }
        }
    }
}
--------------------------------------------------
<1> The `filtered` query accepts both a `query` and a `filter`
<2> A `match_all` is used to return all matching documents.  This is the default
behavior, so in future examples we will simply omit the `query` section
<3> The `term` filter that we saw previously.  Notice how it is placed inside
the `filter` clause.

Once executed, the search results from this query are exactly what you would 
expect: only document `2` is returned as a hit (because only `2` had a price
of 20):

[source,json]
--------------------------------------------------
"hits" : [ 
    {
        "_index" : "my_store",
        "_type" : "products",
        "_id" : "2",
        "_score" : 1.0, <1>
        "_source" : { 
          "price" : 20,
          "productID" : "KDKE-B-9947-#kL5"
        }
    } 
]
--------------------------------------------------
<1> Filters do not perform scoring or relevance. The score comes from the query, 
which is a match_all query, which treats all docs as equal, so all documents 
receive a _neutral_ score of one.

==== Term Filter with Text
As mentioned at the top of this section, the `term` filter can match strings
just as easily as numbers.  Instead of price, let's try to find products that
have a certain UPC identification code.

First, we'll index some product data:

[source,js]
--------------------------------------------------
POST /my_store/products/_bulk
{ "index": { "_id": 1                            }}
{ "price" : 10, "productID" : "XHDK-A-1293-#fJ3" }
{ "index": { "_id": 2                            }}
{ "price" : 20, "productID" : "KDKE-B-9947-#kL5" }
{ "index": { "_id": 3                            }}
{ "price" : 30, "productID" : "JODL-X-1937-#pV7" }
{ "index": { "_id": 4                            }}
{ "price" : 30, "productID" : "QQPX-R-3956-#aD8" }
--------------------------------------------------

Each document has a `productID` which identifies it, and a price.  If we wanted
to find a specific `productID` in SQL, we might use a query like this:

[source,sql]
--------------------------------------------------
SELECT product
FROM products
WHERE productID = "XHDK-A-1293-#fJ3"
--------------------------------------------------

Translated into Elasticsearch DSL, we can try a similar query with
the `term` filter like so:

[source,js]
--------------------------------------------------
GET /my_store/products/_search
{
    "query" : {
        "filtered" : { 
            "filter" : {
                "term" : { 
                    "productID" : "XHDK-A-1293-#fJ3"
                }
            }
        }
    }
}
--------------------------------------------------

Except there is a little hiccup...we won't get any results back!  Why is that?
The problem isn't actually with the the `term` query, it is with the indexed
data.  If we use the Analyze API (<<_testing_analyzers>), we can
see that our UPC is being tokenized into smaller tokens:

[source,js]
--------------------------------------------------
GET /_analyze?field=productID
XHDK-A-1293-#fJ3
--------------------------------------------------
[source,js]
--------------------------------------------------
{
  "tokens" : [ {
    "token" : "xhdk",
    "start_offset" : 0,
    "end_offset" : 4,
    "type" : "<ALPHANUM>",
    "position" : 1
  }, {
    "token" : "1293",
    "start_offset" : 7,
    "end_offset" : 11,
    "type" : "<NUM>",
    "position" : 3
  }, {
    "token" : "fj3",
    "start_offset" : 13,
    "end_offset" : 16,
    "type" : "<ALPHANUM>",
    "position" : 4
  } ]
}
--------------------------------------------------

There are a couple of important points here.  We have three distinct
tokens instead of a single token representing the UPC.  But also notice how
all characters are lowercased, we lost hyphens and the hash (#) sign, and
the `A` was removed entirely because the analyzer thought it was a stop-word.

So when our `term` filter is looking for `XHDK-A-1293-#fJ3`, it doesn't find
anything because that token does not exist inside our index.  Instead, there
are the three tokens listed above.

Obviously, this is not what we want to happen when dealing with identification
codes, or any kind of precise enumeration.

To prevent this from happening, we need to tell Elasticsearch to `not_analyze` 
the field when indexing.  We saw this originally in 
<<_customizing_field_mappings>>.  To do this, we need to first delete our old
index (because it has the incorrect mapping) and create a new one with the 
correct mappings:

[source,js]
--------------------------------------------------
DELETE /my_store <1>

PUT /my_store <2>
{
    "mappings" : {
        "products" : {
            "properties" : {
                "productID" : {
                    "type" : "string",
                    "index" : "not_analyzed" <3>
                }
            }
        }
    }
    
}
--------------------------------------------------
<1> Deleting the index first is required, since we cannot change mappings that
already exist.
<2> With the index deleted, we can recreate it with out custom mapping
<3> Here we explicitly say that we don't want `productID` to be analyzed

Now that we have told Elasticsearch to `not_analyze` the ID field, we can 
go ahead and re-index our documents.

[source,js]
--------------------------------------------------
POST /my_store/products/_bulk
{ "index": { "_id": 1 }}
{ "price" : 10, "productID" : "XHDK-A-1293-#fJ3" }
{ "index": { "_id": 2 }}
{ "price" : 20, "productID" : "KDKE-B-9947-#kL5" }
{ "index": { "_id": 3 }}
{ "price" : 30, "productID" : "JODL-X-1937-#pV7" }
{ "index": { "_id": 4 }}
{ "price" : 30, "productID" : "QQPX-R-3956-#aD8" }
--------------------------------------------------

Only now will our `term` filter work as expected.  Let's try it again on the
newly indexed data (notice, the query and filter have not changed at all, just
how the data is mapped):

[source,js]
--------------------------------------------------
GET /my_store/products/_search
{
    "query" : {
        "filtered" : {
            "filter" : {
                "term" : { 
                    "productID" : "XHDK-A-1293-#fJ3"
                }
            }
        }
    }
}
--------------------------------------------------

Since the `productID` field is not analyzed, and the `term` filter performs no
analysis, the query finds the exact match and returns document `1` as a hit. 
Success!

==== Internal Filter Operation

Internally, Elasticsearch is performing several operations when executing a 
filter:

1. *Find Matching Docs*
+
The `term` filter looks up the term `"XHDK-A-1293-#fJ3"` in the inverted index 
and retrieves the list of documents that contain that term.  In this case, 
only document `1` has the term we are looking for

2. *Build a Bitset*
+
The filter then builds a bitset (array of 1's and 0's) which describes which
documents contain the term.  Matching documents receive a  `1` bit.  In our 
example, the bitset would be: `[1,0,0,0]`

3. *Cache the Bitset*
+
Lastly, the bitset is stored in memory, since we can use this in the future and
skip step 1. and 2.  This adds a lot of performance and makes filters very
fast.

When executing a query that has filters, first check to see if the filter is
cached in memory.  If it is, the cached filter will be retrieved.  Otherwise the
filter will be evaluated (as described above) and the generatead bitset will
be cached for future use.

Once all the relevant bitsets have been retrieved, they are
combined with bitwise operations and yield a final set of documents that match.
These matching documents are then given to the `query` portion of a `filtered`
query.  It is important to understand that the query will only operate on
documents that matched the specified filters...this is one of the ways that
filters can improve performance.  Fewer documents evaluated by the query usually
means faster response times.


