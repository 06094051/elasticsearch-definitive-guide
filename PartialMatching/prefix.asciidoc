
Modern websites which provide a search interface (in particular, e-commerce
applications) often want to provide "autocomplete" functionality.  Autocomplete
is a powerful method to let users quickly find what they are looking for.

The principle is simple: as the user begins to type their query into the search
box, the application provides a list of search results that match what the user
has typed so far.  As the user types more of their query, the search results
narrow and the user is capable of selecting the product they want.

This functionality makes for a great search experience, and users often find
what they are looking for quicker and with less frustration.  So how would you 
implement autocomplete with Elasticsearch?

As the user types, you receive a _prefix_ of the item they are searching for.
For example, the user may enter `ha`.  This could match several documents in 
your index:

* hammer
* ham
* hamper

The user types the next character and you receive the next prefix `ham`.  This 
eliminates the third document, so your search results are only:

* hammer
* ham

The user types an "m" next, making the prefix `hamm`.  This leaves only one
document in the search results (`hammer`), which the user then selects without
having to fully type `hammer`.

Although a very simple example, it clearly demonstrates the concept of _prefix
matching_.  As the user types, you provide Elasticsearch with the prefix, and
Elasticsearch will return a list of documents that start with that particular
fragment.

In practice, this is very easy and accomplished with the `prefix` query:

[source,js]
--------------------------------------------------
{
    "prefix" : { "my_field" : "hamm" }
}
--------------------------------------------------

Elasticsearch is performing a process known as _query rewriting_ when executing
the `prefix`.  Rewritten queries basically take the query, perform some
computation, then rewrite it as a series of `term` queries instead.

For the `prefix` query, the process is fairly straightforward:

1. *Find all terms starting with the prefix*
+
First, we scan over the inverted index to find all terms that start with our 
prefix.  These are collected into a list

2. *Rewrite the query*
+
Once a list of matching terms has been compiled, the query is rewritten as a
`bool` filter/query footnote:[A filter or query is chosen automatically by
Elasticsearch.  See <<_partial_matching_and_relevance_scoring>>].  Each matching term is transformed into a `term` and placed inside the `bool`

3. *Search*
+
Now that the query has been rewritten into a `bool` with multiple `term` clauses,
we can do a search like normal.  Anything returned from this search will
be a document that has a matching prefix.

This process -- rewriting the query before searching -- makes prefix match 
fairly efficient, especially when compared to the naive approach of scanning 
every document for matching prefixes.

.Not Analyzed
****
Important note: the Prefix query is not analyzed.  If you provide a full text 
query, it will be treated as a single token (spaces and all).  If you need 
analysis and full-text prefix matching, we'll cover that in the 
<<_partial_matching_full_text> section shortly
****

==== Suffix Matching
We can use prefix matching to do a neat trick: suffix matching.  Finding suffixes
(words that end with a certain fragment) is a very difficult problem.  There are
dedicated data structures, unsurprisingly called suffix-trees, which can 
tackle this problem.

Unfortunately, suffix-trees are expensive to build and require a lot of memory.
Instead, let's leverage Elasticsearch's token filters and prefix matching.

Let's find all words that end in "ing".  To accomplish this, we are first going
to create an index that has a custom analyzer:

[source,js]
--------------------------------------------------
PUT /my_index
{
    "settings" : {
        "analysis" : {
            "analyzer":{
                "suffix_analyzer":{
                    "filter":[
                        "reverse"
                     ],
                     "type":"custom",
                     "tokenizer":"standard"
                }
            }
        }
    },
    "mappings" : {
        "my_type" : {
            "properties" : {
                "title" : {
                    "type" : "string",
                    "analyzer" : "suffix_analyzer"
                }
            }
        }
    }
}
--------------------------------------------------

It may look complicated, but it is actually very simple.  We first define a 
custom analyzer that includes just a single token filter: `reverse`. This
analyzer will simply reverse the characters in a word, and nothing else.

The `mappings` section then defines a type (`my_type`) that has a single
property (`title`), which is analyzed with our custom `suffix_analyzer`.

Let's index



